{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cb7cea-c882-43a3-a2e2-45ee269e45d8",
   "metadata": {},
   "source": [
    "# Query 2\n",
    "## With DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9e8fcd-9eec-4006-987a-badeabf5c75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1795</td><td>application_1765289937462_1779</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1779/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1779_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1803</td><td>application_1765289937462_1787</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1787/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-61.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1787_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cbc29d-09f9-412b-aaaa-feafac963ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1805</td><td>application_1765289937462_1789</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1789/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-141.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1789_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910990feeda8415e9cd8d7e7082fb2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92b6976ba704e359de0ea6899afe58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----+----+\n",
      "|year|Victim Descent        |#    |%   |\n",
      "+----+----------------------+-----+----+\n",
      "|2025|Hispanic/Latin/Mexican|70   |38.3|\n",
      "|2025|White                 |41   |22.4|\n",
      "|2025|Unknown               |35   |19.1|\n",
      "|2024|Hispanic/Latin/Mexican|30547|29.1|\n",
      "|2024|White                 |24758|23.6|\n",
      "|2024|Unknown               |20784|19.8|\n",
      "|2023|Hispanic/Latin/Mexican|70920|34.7|\n",
      "|2023|White                 |45553|22.3|\n",
      "|2023|Black                 |31247|15.3|\n",
      "|2022|Hispanic/Latin/Mexican|74061|35.8|\n",
      "|2022|White                 |47151|22.8|\n",
      "|2022|Black                 |35064|16.9|\n",
      "|2021|Hispanic/Latin/Mexican|64333|35.2|\n",
      "|2021|White                 |44766|24.5|\n",
      "|2021|Black                 |30423|16.7|\n",
      "|2020|Hispanic/Latin/Mexican|61840|35.5|\n",
      "|2020|White                 |42469|24.4|\n",
      "|2020|Black                 |28395|16.3|\n",
      "|2019|Hispanic/Latin/Mexican|73260|36.5|\n",
      "|2019|White                 |49103|24.5|\n",
      "|2019|Black                 |33395|16.6|\n",
      "|2018|Hispanic/Latin/Mexican|76504|36.5|\n",
      "|2018|White                 |52563|25.1|\n",
      "|2018|Black                 |35500|16.9|\n",
      "|2017|Hispanic/Latin/Mexican|79680|37.4|\n",
      "|2017|White                 |54157|25.4|\n",
      "|2017|Black                 |35300|16.6|\n",
      "|2016|Hispanic/Latin/Mexican|94635|38.9|\n",
      "|2016|White                 |59957|24.6|\n",
      "|2016|Black                 |40666|16.7|\n",
      "|2015|Hispanic/Latin/Mexican|58566|36.6|\n",
      "|2015|White                 |46174|28.9|\n",
      "|2015|Black                 |27595|17.3|\n",
      "|2014|Hispanic/Latin/Mexican|68359|38.4|\n",
      "|2014|White                 |47327|26.6|\n",
      "|2014|Black                 |32898|18.5|\n",
      "|2013|Hispanic/Latin/Mexican|66408|38.0|\n",
      "|2013|White                 |48348|27.6|\n",
      "|2013|Black                 |31905|18.2|\n",
      "|2012|Hispanic/Latin/Mexican|69785|38.3|\n",
      "|2012|White                 |51462|28.2|\n",
      "|2012|Black                 |33253|18.2|\n",
      "|2011|Hispanic/Latin/Mexican|69344|38.6|\n",
      "|2011|White                 |50641|28.2|\n",
      "|2011|Black                 |32046|17.8|\n",
      "|2010|Hispanic/Latin/Mexican|70174|38.9|\n",
      "|2010|White                 |51551|28.5|\n",
      "|2010|Black                 |32566|18.0|\n",
      "+----+----------------------+-----+----+\n",
      "\n",
      "Execution time: 24.393282413482666 sec"
     ]
    }
   ],
   "source": [
    "# We initialized a spark session with specific configurations, now we import\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, to_timestamp, year, count, sum, row_number, round, when\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "#Beginning of timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Define schema for crime data DataFrame\n",
    "crime_data_full_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType())\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "crime_data_full_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_data_full_schema) \n",
    "\n",
    "crime_data_df = crime_data_full_df.select(\"DR_NO\", \"Date Rptd\", \"Vict Descent\")\n",
    "\n",
    "# Find the year\n",
    "crime_data_with_year_df = crime_data_df.withColumn(\n",
    "    'Timestamp', to_timestamp(col('Date Rptd'), 'yyyy MMM dd hh:mm:ss a') ) \\\n",
    "    .withColumn('year', year(col('Timestamp')))\n",
    "\n",
    "analysis_df = crime_data_with_year_df.select(\"DR_NO\", \"Vict Descent\", \"year\") \\\n",
    "    .filter(col(\"year\").isNotNull() & col(\"Vict Descent\").isNotNull())\n",
    "\n",
    "# Group by Year and Descent and then count\n",
    "grouped_df = analysis_df.groupBy(\"year\", \"Vict Descent\").agg(\n",
    "    count(col(\"DR_NO\")).alias(\"#\"))\n",
    "\n",
    "# Window functions for ranking and total count per year for percentage calculation\n",
    "window_year_total = Window.partitionBy(\"year\")\n",
    "\n",
    "window_ranking = Window.partitionBy(\"year\").orderBy(col(\"#\").desc())\n",
    "\n",
    "ranked_df = grouped_df.withColumn(\"Total_Year_Count\", sum(col(\"#\")).over(window_year_total)) \\\n",
    "    .withColumn(\"Rank\", row_number().over(window_ranking)) \\\n",
    "    .withColumn(\"%\", round((col(\"#\") / col(\"Total_Year_Count\")) * 100, 1))\n",
    "\n",
    "# Convert Vict Descent to full version\n",
    "descent_mapping = (\n",
    "    when(col(\"Vict Descent\") == \"A\", \"Other Asian\") \n",
    "    .when(col(\"Vict Descent\") == \"B\", \"Black\")\n",
    "    .when(col(\"Vict Descent\") == \"C\", \"Chinese\")\n",
    "    .when(col(\"Vict Descent\") == \"D\", \"Cambodian\")\n",
    "    .when(col(\"Vict Descent\") == \"F\", \"Filipino\")\n",
    "    .when(col(\"Vict Descent\") == \"G\", \"Guamanian\")\n",
    "    .when(col(\"Vict Descent\") == \"H\", \"Hispanic/Latin/Mexican\")\n",
    "    .when(col(\"Vict Descent\") == \"I\", \"American Indian\")\n",
    "    .when(col(\"Vict Descent\") == \"J\", \"Japanese\")\n",
    "    .when(col(\"Vict Descent\") == \"K\", \"Korean\")\n",
    "    .when(col(\"Vict Descent\") == \"L\", \"Laotian\")\n",
    "    .when(col(\"Vict Descent\") == \"O\", \"Other\")\n",
    "    .when(col(\"Vict Descent\") == \"P\", \"Pacific Islander\")\n",
    "    .when(col(\"Vict Descent\") == \"S\", \"Samoan\")\n",
    "    .when(col(\"Vict Descent\") == \"U\", \"Hawaiian\")\n",
    "    .when(col(\"Vict Descent\") == \"V\", \"Vietnamese\")\n",
    "    .when(col(\"Vict Descent\") == \"W\", \"White\")\n",
    "    .when(col(\"Vict Descent\") == \"X\", \"Unknown\")\n",
    "    .when(col(\"Vict Descent\") == \"Z\", \"Asian Indian\")\n",
    "    .otherwise(col(\"Vict Descent\"))\n",
    ")\n",
    "\n",
    "ranked_df_mapped = ranked_df.withColumn(\"Victim Descent\", descent_mapping)\n",
    "\n",
    "# Filtering for final output\n",
    "final_result_df = ranked_df_mapped.filter(col(\"Rank\") <= 3) \\\n",
    "    .select(\n",
    "    col(\"year\"),\n",
    "    col(\"Victim Descent\"), \n",
    "    col(\"#\"),\n",
    "    col(\"%\"),) \\\n",
    "    .orderBy(\n",
    "    col(\"year\").desc(), \n",
    "    col(\"Rank\").asc())\n",
    "\n",
    "# Show results\n",
    "final_result_df.show(48, truncate=False)\n",
    "\n",
    "# End of timing\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e3059-0c60-4780-9385-c5534b95d599",
   "metadata": {},
   "source": [
    "## SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d27340-14cc-4411-8166-09d02c214775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133166784c6e401daff773bd641f3f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----+----+\n",
      "|year|Victim Descent        |#    |%   |\n",
      "+----+----------------------+-----+----+\n",
      "|2025|Hispanic/Latin/Mexican|70   |38.3|\n",
      "|2025|White                 |41   |22.4|\n",
      "|2025|Unknown               |35   |19.1|\n",
      "|2024|Hispanic/Latin/Mexican|30547|29.1|\n",
      "|2024|White                 |24758|23.6|\n",
      "|2024|Unknown               |20784|19.8|\n",
      "|2023|Hispanic/Latin/Mexican|70920|34.7|\n",
      "|2023|White                 |45553|22.3|\n",
      "|2023|Black                 |31247|15.3|\n",
      "|2022|Hispanic/Latin/Mexican|74061|35.8|\n",
      "|2022|White                 |47151|22.8|\n",
      "|2022|Black                 |35064|16.9|\n",
      "|2021|Hispanic/Latin/Mexican|64333|35.2|\n",
      "|2021|White                 |44766|24.5|\n",
      "|2021|Black                 |30423|16.7|\n",
      "|2020|Hispanic/Latin/Mexican|61840|35.5|\n",
      "|2020|White                 |42469|24.4|\n",
      "|2020|Black                 |28395|16.3|\n",
      "|2019|Hispanic/Latin/Mexican|73260|36.5|\n",
      "|2019|White                 |49103|24.5|\n",
      "|2019|Black                 |33395|16.6|\n",
      "|2018|Hispanic/Latin/Mexican|76504|36.5|\n",
      "|2018|White                 |52563|25.1|\n",
      "|2018|Black                 |35500|16.9|\n",
      "|2017|Hispanic/Latin/Mexican|79680|37.4|\n",
      "|2017|White                 |54157|25.4|\n",
      "|2017|Black                 |35300|16.6|\n",
      "|2016|Hispanic/Latin/Mexican|94635|38.9|\n",
      "|2016|White                 |59957|24.6|\n",
      "|2016|Black                 |40666|16.7|\n",
      "|2015|Hispanic/Latin/Mexican|58566|36.6|\n",
      "|2015|White                 |46174|28.9|\n",
      "|2015|Black                 |27595|17.3|\n",
      "|2014|Hispanic/Latin/Mexican|68359|38.4|\n",
      "|2014|White                 |47327|26.6|\n",
      "|2014|Black                 |32898|18.5|\n",
      "|2013|Hispanic/Latin/Mexican|66408|38.0|\n",
      "|2013|White                 |48348|27.6|\n",
      "|2013|Black                 |31905|18.2|\n",
      "|2012|Hispanic/Latin/Mexican|69785|38.3|\n",
      "|2012|White                 |51462|28.2|\n",
      "|2012|Black                 |33253|18.2|\n",
      "|2011|Hispanic/Latin/Mexican|69344|38.6|\n",
      "|2011|White                 |50641|28.2|\n",
      "|2011|Black                 |32046|17.8|\n",
      "|2010|Hispanic/Latin/Mexican|70174|38.9|\n",
      "|2010|White                 |51551|28.5|\n",
      "|2010|Black                 |32566|18.0|\n",
      "+----+----------------------+-----+----+\n",
      "\n",
      "\n",
      "Execution time: 14.385581731796265 seconds"
     ]
    }
   ],
   "source": [
    "# We initialized a spark session with specific configurations, now we import\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import time\n",
    "\n",
    "#Beginning of timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Define schema for crime data DataFrame\n",
    "crime_data_full_schema = StructType([\n",
    "    StructField(\"DR_NO\", IntegerType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", IntegerType()),\n",
    "    StructField(\"AREA\", IntegerType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", IntegerType()),\n",
    "    StructField(\"Part 1-2\", IntegerType()),\n",
    "    StructField(\"Crm Cd\", IntegerType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", IntegerType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType())\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "crime_data_full_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/\", \\\n",
    "    header=True, \\\n",
    "    schema=crime_data_full_schema) \n",
    "\n",
    "crime_data_df = crime_data_full_df.select(\"DR_NO\", \"Date Rptd\", \"Vict Descent\")\n",
    "\n",
    "# Create temporary table for SQL queries\n",
    "crime_data_df.createOrReplaceTempView(\"crime_data_table\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "WITH PreprocessedData AS (\n",
    "    SELECT\n",
    "        DR_NO,\n",
    "        `Vict Descent`, \n",
    "        \n",
    "        -- Find the year\n",
    "        YEAR(TO_TIMESTAMP(`Date Rptd`, 'yyyy MMM dd hh:mm:ss a')) AS year,\n",
    "        \n",
    "        -- 2. Descent mapping\n",
    "        CASE `Vict Descent`\n",
    "            WHEN 'A' THEN 'Other Asian'\n",
    "            WHEN 'B' THEN 'Black'\n",
    "            WHEN 'C' THEN 'Chinese'\n",
    "            WHEN 'D' THEN 'Cambodian'\n",
    "            WHEN 'F' THEN 'Filipino'\n",
    "            WHEN 'G' THEN 'Guamanian'\n",
    "            WHEN 'H' THEN 'Hispanic/Latin/Mexican'\n",
    "            WHEN 'I' THEN 'American Indian'\n",
    "            WHEN 'J' THEN 'Japanese'\n",
    "            WHEN 'K' THEN 'Korean'\n",
    "            WHEN 'L' THEN 'Laotian'\n",
    "            WHEN 'O' THEN 'Other'\n",
    "            WHEN 'P' THEN 'Pacific Islander'\n",
    "            WHEN 'S' THEN 'Samoan'\n",
    "            WHEN 'U' THEN 'Hawaiian'\n",
    "            WHEN 'V' THEN 'Vietnamese'\n",
    "            WHEN 'W' THEN 'White'\n",
    "            WHEN 'X' THEN 'Unknown'\n",
    "            WHEN 'Z' THEN 'Asian Indian'\n",
    "            ELSE `Vict Descent`\n",
    "        END AS `Victim Descent`\n",
    "    FROM crime_data_table\n",
    "    \n",
    "    -- Filter out null values\n",
    "    WHERE YEAR(TO_TIMESTAMP(`Date Rptd`, 'yyyy MMM dd hh:mm:ss a')) IS NOT NULL\n",
    "      AND `Vict Descent` IS NOT NULL\n",
    "),\n",
    "RankedData AS (\n",
    "    SELECT\n",
    "        year,\n",
    "        `Victim Descent`,\n",
    "        \n",
    "        -- Count of incidents for this Descent/Year group\n",
    "        COUNT(DR_NO) AS `Count_#`,\n",
    "        \n",
    "        -- Total Count for the Year (Window Function)\n",
    "        SUM(COUNT(DR_NO)) OVER (PARTITION BY year) AS Total_Year_Count,\n",
    "        \n",
    "        -- Rank within the Year (Window Function)\n",
    "        ROW_NUMBER() OVER (PARTITION BY year ORDER BY COUNT(DR_NO) DESC) AS Rank\n",
    "    FROM PreprocessedData\n",
    "    GROUP BY year, `Victim Descent`\n",
    ")\n",
    "SELECT\n",
    "    year,\n",
    "    `Victim Descent`,\n",
    "    `Count_#` AS `#`,\n",
    "    \n",
    "    -- Calculate percentage\n",
    "    ROUND((`Count_#` / Total_Year_Count) * 100, 1) AS `%`\n",
    "FROM RankedData\n",
    "WHERE Rank <= 3 -- Final filtering\n",
    "ORDER BY year DESC, Rank ASC\n",
    "\"\"\"\n",
    "\n",
    "# SQL Query execution\n",
    "final_result_sql_df = spark.sql(sql_query)\n",
    "\n",
    "# Final results\n",
    "final_result_sql_df.show(48, truncate=False) \n",
    "\n",
    "# End of timing\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"\\nExecution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1b383-d851-40a7-a94d-272eb3489d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
